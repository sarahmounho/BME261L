{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine-Learning Pipeline for BME261L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "#other \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  heart_rate  motion_x  motion_y  motion_z  label\n",
      "0   390          57  0.017487 -0.586700 -0.805771      0\n",
      "1   420          56  0.018982 -0.589676 -0.809158      0\n",
      "2   450          56  0.020966 -0.580887 -0.815048      0\n",
      "3   480          57  0.019485 -0.580872 -0.813583      0\n",
      "4   510          59  0.016998 -0.587204 -0.806259      0\n",
      "5   540          61  0.019959 -0.593094 -0.806198      0\n",
      "6   570          98  0.024399 -0.586258 -0.811585      0\n",
      "7   600          90  0.017929 -0.565567 -0.803955      0\n",
      "8   630          94  0.018967 -0.579376 -0.810684      0\n",
      "9   660          88  0.033249 -0.592117 -0.807114      0\n",
      "(554, 6)\n"
     ]
    }
   ],
   "source": [
    "#Read in CSV\n",
    "col_names = ['heart_rate', 'motion', 'time', 'labels']\n",
    "heart_rate_txt = 'C:/Users/sarah/OneDrive/Documents/BME261L/Data_Analysis/Dummy_Data/heart_rate/46343_heartrate.txt'\n",
    "motion_txt = 'C:/Users/sarah/OneDrive/Documents/BME261L/Data_Analysis/Dummy_Data/motion/46343_acceleration.csv'\n",
    "label_txt = 'C:/Users/sarah/OneDrive/Documents/BME261L/Data_Analysis/Dummy_Data/labels/46343_labeled_sleep.csv'\n",
    "heart_rate = pd.read_csv(heart_rate_txt, names=['time','heart_rate'])\n",
    "motion = pd.read_csv(motion_txt, names=['time','motion_x', 'motion_y', 'motion_z'])\n",
    "labels = pd.read_csv(label_txt, names=['time', 'label'])\n",
    "\n",
    "#preview data\n",
    "#print(heart_rate.shape)\n",
    "#print(motion.shape)\n",
    "#print(labels.shape)\n",
    "#print(heart_rate.head(10))\n",
    "#print(motion.head(10))\n",
    "#print(labels.head(10))\n",
    "\n",
    "#I will just use the first 554 data points, even though I don't\n",
    "#think this is the actual correct labeled data. We will not be\n",
    "#using this data to select the actual model, so I am not concerned.\n",
    "\n",
    "#create one df\n",
    "data = pd.DataFrame()\n",
    "data['time'] = labels.iloc[:, 0]\n",
    "#append heart rate\n",
    "data['heart_rate'] = heart_rate.iloc[0:554, 1]\n",
    "#append motion\n",
    "data['motion_x'] = motion.iloc[0:554, 1]\n",
    "data['motion_y'] = motion.iloc[0:554, 2]\n",
    "data['motion_z'] = motion.iloc[0:554, 3]\n",
    "#append labels\n",
    "data['label'] = labels.iloc[:, 1]\n",
    "print(data.head(10))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate features from label\n",
    "data_X = data.iloc[:, 0:5]\n",
    "data_Y = data.iloc[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.58      0.52        85\n",
      "           1       0.07      0.07      0.07        29\n",
      "           2       0.59      0.32      0.42       170\n",
      "           3       0.62      0.67      0.64       156\n",
      "           5       0.55      0.77      0.64       114\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       554\n",
      "   macro avg       0.46      0.48      0.46       554\n",
      "weighted avg       0.54      0.54      0.52       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "#create a scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "#create a pipeline that does scaling, then KNN (prevent data leakage)\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('knn', knn)])\n",
    "#Set up parameters to fine tune\n",
    "#check nearest neighbors 1-30\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1, 30))\n",
    "}\n",
    "#Pass the pipeline and the parameters into a GridSearchCV with a 5-fold CV\n",
    "clf = GridSearchCV(pipe, param_grid, cv=5)\n",
    "Y_pred = cross_val_predict(clf, data_X, data_Y, cv=5)\n",
    "#Report\n",
    "report = classification_report(data_Y, Y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.05      0.08        85\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.41      0.55      0.47       170\n",
      "           3       0.31      0.42      0.36       156\n",
      "           5       0.16      0.13      0.15       114\n",
      "\n",
      "   micro avg       0.32      0.32      0.32       554\n",
      "   macro avg       0.21      0.23      0.21       554\n",
      "weighted avg       0.27      0.32      0.29       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "#create a NB classifier\n",
    "clf = GaussianNB()\n",
    "#fit with a 10-fold CV\n",
    "Y_pred = cross_val_predict(clf, data_X, data_Y, cv=10)\n",
    "#Report\n",
    "report = classification_report(data_Y, Y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        85\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.37      0.56      0.44       170\n",
      "           3       0.54      0.56      0.55       156\n",
      "           5       0.35      0.41      0.38       114\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       554\n",
      "   macro avg       0.25      0.31      0.28       554\n",
      "weighted avg       0.34      0.42      0.37       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "#create a scalar\n",
    "scalar = MinMaxScaler()\n",
    "#create a SVM classifier\n",
    "svm = SVC()\n",
    "#create a pipeline that does scaling, then SVM\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('svm', svm)])\n",
    "#Set up parameters to fine tune\n",
    "#tune for best kernel\n",
    "param_grid = {\n",
    "    'svm__kernel':['linear', 'rbf', 'poly', 'sigmoid']\n",
    "    }\n",
    "#grid search and CV\n",
    "clf = GridSearchCV(pipe, param_grid, cv=5)\n",
    "Y_pred = cross_val_predict(clf, data_X, data_Y, cv=5)\n",
    "#Report\n",
    "report = classification_report(data_Y, Y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.06      0.10        85\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.36      0.48      0.41       170\n",
      "           3       0.55      0.67      0.60       156\n",
      "           5       0.33      0.36      0.35       114\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       554\n",
      "   macro avg       0.31      0.31      0.29       554\n",
      "weighted avg       0.38      0.42      0.38       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Neural Net\n",
    "#create a scalar\n",
    "scalar = MinMaxScaler()\n",
    "#create a Nueral Net classifier\n",
    "mlp = MLPClassifier()\n",
    "#create a pipeline that does scaling, then SVM\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('mlp', mlp)])\n",
    "#Set up parameters to fine tune\n",
    "#tune for best hidden layer size and activation\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(10,), (20,), (30,),\n",
    "                                (40,), (50,), (60,)],\n",
    "    'mlp__activation': ['logistic', 'tanh', 'relu']\n",
    "    }\n",
    "#grid search and CV\n",
    "clf = GridSearchCV(pipe, param_grid, cv=5)\n",
    "Y_pred = cross_val_predict(clf, data_X, data_Y, cv=5)\n",
    "#Report\n",
    "report = classification_report(data_Y, Y_pred)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.65        85\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.52      0.44      0.48       170\n",
      "           3       0.64      0.83      0.73       156\n",
      "           5       0.64      0.65      0.65       114\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       554\n",
      "   macro avg       0.49      0.52      0.50       554\n",
      "weighted avg       0.57      0.60      0.58       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "#create a random forest classifier\n",
    "rfc = RFC()\n",
    "#Set up parameters to fine tune\n",
    "#tune for best max depth, min samples per leaf and max features\n",
    "max_depth_lst = list(range(35,56))\n",
    "param_grid = {'max_depth': max_depth_lst,\n",
    "              'min_samples_leaf': [8, 10, 12],\n",
    "              'max_features': ['sqrt', 'log2']}\n",
    "#grid search and CV\n",
    "clf = GridSearchCV(rfc, param_grid, cv=5)\n",
    "Y_pred = cross_val_predict(clf, data_X, data_Y, cv=5)\n",
    "#Report\n",
    "report = classification_report(data_Y, Y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.31      0.38        85\n",
      "           1       0.19      0.10      0.13        29\n",
      "           2       0.34      0.56      0.43       170\n",
      "           3       0.49      0.52      0.50       156\n",
      "           5       0.87      0.35      0.50       114\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       554\n",
      "   macro avg       0.48      0.37      0.39       554\n",
      "weighted avg       0.51      0.44      0.44       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AdaBoostClassifier\n",
    "#create an AdaBoostClassifier\n",
    "abc = ABC()\n",
    "#params\n",
    "est_lst = list(range(50,251, 25))\n",
    "param_grid = {'n_estimators': est_lst}\n",
    "#grid search \n",
    "clf = GridSearchCV(abc, param_grid, cv=5)\n",
    "#cross validation\n",
    "Y_pred = cross_val_predict(clf, data_X, data_Y, cv=5)\n",
    "#Report\n",
    "report = classification_report(data_Y, Y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
